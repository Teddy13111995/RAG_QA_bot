{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLtWteB_qT04"
   },
   "source": [
    "1. Install the Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gvzTrkh0oUSK",
    "outputId": "d57f26a5-a56c-4013-e05d-ffb6e103aaee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.93.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.26.3-cp39-abi3-macosx_11_0_arm64.whl.metadata (3.4 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting pinecone\n",
      "  Downloading pinecone-7.3.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp311-cp311-macosx_14_0_arm64.whl.metadata (4.8 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.53.1-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.8.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/ParkEV_py311/lib/python3.11/site-packages (from openai) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/ParkEV_py311/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/ParkEV_py311/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/envs/ParkEV_py311/lib/python3.11/site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/ParkEV_py311/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/ParkEV_py311/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/ParkEV_py311/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/ParkEV_py311/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.33.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.66 (from langchain)\n",
      "  Downloading langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.4-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.41-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/envs/ParkEV_py311/lib/python3.11/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/ParkEV_py311/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/ParkEV_py311/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/ParkEV_py311/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/ParkEV_py311/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Collecting pinecone-plugin-assistant<2.0.0,>=1.6.0 (from pinecone)\n",
      "  Downloading pinecone_plugin_assistant-1.7.0-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone)\n",
      "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/anaconda3/envs/ParkEV_py311/lib/python3.11/site-packages (from pinecone) (2.9.0.post0)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.7.1-cp311-none-macosx_11_0_arm64.whl.metadata (29 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.7.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.16.0-cp311-cp311-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.33.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/envs/ParkEV_py311/lib/python3.11/site-packages (from sentence-transformers) (11.3.0)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/ParkEV_py311/lib/python3.11/site-packages (from transformers) (2.3.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.2-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-macosx_11_0_arm64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/envs/ParkEV_py311/lib/python3.11/site-packages (from accelerate) (7.0.0)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.18-cp311-cp311-macosx_15_0_arm64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/ParkEV_py311/lib/python3.11/site-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/ParkEV_py311/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/ParkEV_py311/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading openai-1.93.0-py3-none-any.whl (755 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.0/755.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n",
      "\u001b[?25hUsing cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.10.0-cp311-cp311-macosx_11_0_arm64.whl (321 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp311-cp311-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.68-py3-none-any.whl (441 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading sqlalchemy-2.0.41-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading pymupdf-1.26.3-cp39-abi3-macosx_11_0_arm64.whl (22.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading pinecone-7.3.0-py3-none-any.whl (587 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.6/587.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pinecone_plugin_assistant-1.7.0-py3-none-any.whl (239 kB)\n",
      "Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Downloading sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "Downloading transformers-4.53.1-py3-none-any.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.33.2-py3-none-any.whl (515 kB)\n",
      "Downloading hf_xet-1.1.5-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.2-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading faiss_cpu-1.11.0-cp311-cp311-macosx_14_0_arm64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.8.1-py3-none-any.whl (365 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Downloading langsmith-0.4.4-py3-none-any.whl (367 kB)\n",
      "Downloading orjson-3.10.18-cp311-cp311-macosx_15_0_arm64.whl (133 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading zstandard-0.23.0-cp311-cp311-macosx_11_0_arm64.whl (633 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m633.7/633.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Downloading torch-2.7.1-cp311-none-macosx_11_0_arm64.whl (68.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.0-cp311-cp311-macosx_12_0_arm64.whl (10.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading scipy-1.16.0-cp311-cp311-macosx_14_0_arm64.whl (20.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: mpmath, zstandard, typing-inspection, tqdm, threadpoolctl, tenacity, sympy, SQLAlchemy, scipy, safetensors, regex, pymupdf, pydantic-core, pinecone-plugin-interface, packaging, orjson, networkx, jsonpatch, joblib, jiter, hf-xet, fsspec, filelock, distro, annotated-types, torch, scikit-learn, requests-toolbelt, pydantic, pinecone-plugin-assistant, huggingface-hub, faiss-cpu, tokenizers, pinecone, openai, langsmith, accelerate, transformers, langchain-core, sentence-transformers, langchain-text-splitters, langchain\n",
      "\u001b[2K  Attempting uninstall: packaging[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/42\u001b[0m [pymupdf]my]\n",
      "\u001b[2K    Found existing installation: packaging 25.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/42\u001b[0m [pymupdf]\n",
      "\u001b[2K    Uninstalling packaging-25.0:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/42\u001b[0m [pymupdf]\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/42\u001b[0m [pymupdf]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42/42\u001b[0m [langchain]angchain]angchain-core]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed SQLAlchemy-2.0.41 accelerate-1.8.1 annotated-types-0.7.0 distro-1.9.0 faiss-cpu-1.11.0 filelock-3.18.0 fsspec-2025.5.1 hf-xet-1.1.5 huggingface-hub-0.33.2 jiter-0.10.0 joblib-1.5.1 jsonpatch-1.33 langchain-0.3.26 langchain-core-0.3.68 langchain-text-splitters-0.3.8 langsmith-0.4.4 mpmath-1.3.0 networkx-3.5 openai-1.93.0 orjson-3.10.18 packaging-24.2 pinecone-7.3.0 pinecone-plugin-assistant-1.7.0 pinecone-plugin-interface-0.0.7 pydantic-2.11.7 pydantic-core-2.33.2 pymupdf-1.26.3 regex-2024.11.6 requests-toolbelt-1.0.0 safetensors-0.5.3 scikit-learn-1.7.0 scipy-1.16.0 sentence-transformers-5.0.0 sympy-1.14.0 tenacity-9.1.2 threadpoolctl-3.6.0 tokenizers-0.21.2 torch-2.7.1 tqdm-4.67.1 transformers-4.53.1 typing-inspection-0.4.1 zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai langchain pymupdf tqdm pinecone sentence-transformers faiss-cpu transformers accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1uAVcpbGqeSY"
   },
   "source": [
    "2. Import the required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9K0ztopXoXp6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ParkEV_py311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz\n",
    "import faiss\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# from google.colab import files\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone\n",
    "from IPython.display import FileLink, FileLinks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6P_gkCwsqw0E"
   },
   "source": [
    "3. Set OpenAi API Key, Pinecone API Key and Pinecone Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OmEeTfoKocBQ",
    "outputId": "c3aac1d7-6d5c-4fe7-b7a7-52170e05d1a1"
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "openai_api_key = getpass.getpass(\"Enter your OpenAI API Key: \")\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "pinecone_api_key = getpass.getpass(\"Enter your Pinecone API Key: \")\n",
    "os.environ[\"PINECONE_API_KEY\"] = pinecone_api_key\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "index_name = input(\"Enter Index Name\")\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08GBQQWAqy-X"
   },
   "source": [
    "4. Upload the required files (I am Loading my Resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "9KUCZOGLoiAS",
    "outputId": "f52c569a-f972-441f-940b-0b1e64ae91f3"
   },
   "outputs": [],
   "source": [
    "uploaded_files = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pfaMLicrKLC"
   },
   "source": [
    "5. Extraction and splitting Text from uploaded file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cffXLmh8oqCv",
    "outputId": "8337fbb9-e909-45e8-fd4f-3cbaa60271c0"
   },
   "outputs": [],
   "source": [
    "def extract_text_from_file(file_path):\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        doc = fitz.open(file_path)\n",
    "        return \"\\n\".join([page.get_text() for page in doc])\n",
    "    elif file_path.endswith(\".txt\"):\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return f.read()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "documents = []\n",
    "for filename in uploaded_files.keys():\n",
    "    raw_text = extract_text_from_file(filename)\n",
    "    chunks = text_splitter.split_text(raw_text)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        documents.append({\"id\": f\"{filename}-{i}\", \"text\": chunk, \"metadata\": {\"source\": filename}})\n",
    "print(f\"Chunks Created: {len(documents)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHB0Q1_MrbyN"
   },
   "source": [
    "6. Generate Embeddings and creating FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523,
     "referenced_widgets": [
      "facb24c023a94da78b61206402ff8012",
      "bd167c0372ff4c19b755c36865ae3622",
      "d63830f0bd8f4fa899d09b513f68e627",
      "0b7c1b9b75de4d7c898db539730cb6db",
      "89b1b0e3a9194d59a56e0e56a1fddf5a",
      "17bc81b064cb4eccab895d5353610e7b",
      "0eb1f3647dad4a059bec92c03e76c902",
      "e6d996189bb54a298c98bbaf568ba5fa",
      "fe4be9f415f949dea46828db73bb1b95",
      "b1e260d58abb45aa8ff17cc04400ab82",
      "3728fa63a77e48808ea5afab1b6e5631",
      "6977030098b44728bb2aba5564b096c4",
      "882226fd2d5c4ce0a17a7cb0bb5fe145",
      "cd141e040bcb4326b48df109f18aa6d3",
      "c7b2c5e6609247df96a380c8062c1e50",
      "c2edff211f454fa3b4f246565c5deede",
      "1675042d03d242bd98844492f49e306e",
      "5e97c47ad95a4a85a343c26afda6d40e",
      "b7b3bc40928d4c9c8f97d7cf0b48e066",
      "63c2ab87a5d64584bb461092ca9e4a1b",
      "198ab335f9874311b4602e8b075d4a59",
      "abf768de25324f2d90cb23bdab70650f",
      "daecf86010164f63bd18c4a654a6284c",
      "60f6b9d7b62947a6a0f2ee71d8d71765",
      "dd634510612c4cb7993be799fcfabdbc",
      "00a4075f048f48beaf3467517a2c52f1",
      "979b40a3fad740349b7cf5d6b6fd53a7",
      "30e5141f8b284448aba35a4eb70b4574",
      "1b27dc01faed4cbbb51cfb32cbbcb45b",
      "07714097a1294685a4bc2631ebaf6726",
      "2ca1d0ca3e0c42508e92d25262ac4e47",
      "291fbcdc0df341eaa6ea060fb0adac38",
      "852c230af9064264a9ed5c50ef201807",
      "757adb294d224f199a303d0ad67eeac6",
      "8952a9b653754e5c94885e38f3213665",
      "7bee6f25680f4b6bbe572e037ca9e52c",
      "603c376424c84efabbb17bd7cfb33e27",
      "e3f503dbdc8b4b09b65fe9761ebcc104",
      "c57c752e11974833a570501d21c70b0c",
      "3b3329c7b45b459f81f7cb1f14418c18",
      "a10e6d74fb2641068b332e69961478f0",
      "5d2ab0ff320f464c93d8e45d66433f78",
      "a3bc7d5983b34977aa700b7f8bae9216",
      "fe0885b903e04e68a8dd210836e38b90",
      "d79fc0e2392945d29a0387d28afd72e5",
      "af989e238d1f45db90f3fabeb45b5860",
      "deb18295e53b4cb4a1d8299117b9629d",
      "dbd203e774234d02a88e0e423b859cf9",
      "cbf8f7e67b5346b4928beba0e151234c",
      "a06723767b4441e1ade981192c379324",
      "b650c887e8774e29a4a9176ca9a205cf",
      "5be352addf064fbaa77619f3a7880466",
      "f16ea0b47c8c4d368adbe2df8a4ad15b",
      "cb53ad89125a408b8a4ae15966897537",
      "6529396d06e44ab6b96ca207a1e86f18",
      "9f551a22932247b5b8af7e72edf9c8a3",
      "80294d8f4c22495ba9b6d00384e8e24b",
      "be952b6fd2a140a0a3d4300fbad77303",
      "88eb1232344e449dbe43b047b8b94277",
      "5101b8b3d4064568a45c15fca685ab6e",
      "7ab01a43876d4e5fb688bf5065403c76",
      "a2a1526ebfec496c86884dbe7cb2aecf",
      "2d11949ed20b460c91bc83f00928eaf0",
      "dfe27317fcfc494faf377411f3c00c8e",
      "7d393832561d4ff0a0629134c2507fa2",
      "0cfddc2beee046a094c02f2dd24b7844",
      "e3a950813dc642428a63d2103db3f31a",
      "c4546b421f6444d99e6d42d6b267108a",
      "b3b90aa9604a4c03b21929c712947447",
      "3360ef5b7a904311bddf5a8287d3a8b6",
      "d3d07b98d72a41a8bff68697f0b7c8f6",
      "c5b621b40f2040c9abf8f49783bfbab4",
      "2be9c84ab98e41ff9494f3f4880e0364",
      "cd18015fb19f406bb6295de682f3934e",
      "5779d8bd62014647b9b1d524f00982a0",
      "77a86cd6f02b402fb8bbdb6b9ce0e277",
      "9928e541c79d400491595447697b483f",
      "841c445de08049968dc7d4794dd42776",
      "c3034b05fa45425a93133eb66c20a63d",
      "4ef9d23a368040de8638fac7986a0630",
      "f8ca3c55aa1e4a138e566855391b8ac2",
      "4aaa31ea2441490a81c40ade5e885f6f",
      "34700ea555e343e6952a48424becf73d",
      "f6079a68166b4940b7cafb5e9a497890",
      "7a78f3152ab44a988726ec75e26faf3f",
      "d15042df54224c568ef81b4bc89cbd89",
      "9b54e60077f040c78f61d92389ed1ce3",
      "816f4b30712543dcaf861b1800c1edd0",
      "710ae10b87d047ceb6a1ca35982d829e",
      "b67e7d31894d430a8959c8f15e795834",
      "0c6250695f334b509f04826944700aad",
      "1b7e27feb6ce4142b9da0f001c83fd38",
      "5e51c45a50ea4d40b97b76e654d46c3d",
      "875d4ff8bf084a8683a818887f8212f2",
      "c7e80d12e280439fa188fa15ce537d87",
      "6327467a7fb5481dae3971b353f160f0",
      "70d65f55358d4f9587b1b282a5feba7d",
      "ec4bce51308c4b838678daebe43ec21b",
      "8fb59c46a5b741eebdacae753e01efc8",
      "41216efd92b14372886407bad188c18b",
      "1239b28514c54333b04852e58780819a",
      "175bead225fd4c0a98fd1c9b277b6614",
      "21875d9fd2cc43faa8fb34d95e84a9aa",
      "c89d750c26a34a658fa7f2c8dc7cf3c7",
      "16f8bf83b85a446c9e5cc574d82ad146",
      "91c8457b90b04dc3a4c91804aa09eaec",
      "cdde66328e21463e8dd2e42d5276e473",
      "38e1503a5baf402eb21a87ce3f7ec648",
      "1cdd7ccec118496aba75c9d47aeb52d1",
      "fef3a64f0fab4c3f8d323de5d04f5860",
      "db71277ac1bb4576ba750bd23b415666",
      "33f7de228ba4462c8a74ce68df728279",
      "c80f9409e651463c8567b07e58a3c856",
      "c419932601f34583964a75aff3a14c93",
      "14d3cebb5cec4726be7322745f9aec66",
      "952df88d2491404abef4413bc922d539",
      "5c64eff06e54489f82c634074d413249",
      "0f78923dfb924d9e82bc4e84d1f55d01",
      "dddfeafd2b504d1ca4a7c3710c02426e",
      "1ded3e1a8e3a41aa88deca0045dc1f7f",
      "ce880db5cde548d1b94cd6cb3ab9507f",
      "fddbcf6b549841f898b5cd0a07b8f1fc",
      "c0cb1b20b6a74128bb80e09c5d7a2874",
      "e6ddbebc1fa34951ba35be6dd1342e37",
      "e3a9f8ddcca9405799309277bd465a54",
      "a2ceaadacfcb49f292919f101dc73f98",
      "f5687f1554ce411b8033eec03c7d7791",
      "ff87293a681d4536b9e958670e5fcc7e",
      "df4ce51728cf4029b159e621ba8dcc65",
      "4becbeefe2344dd592a6117a559aa1fd",
      "98117a76b52a491b8ca314a81ed4a54d",
      "bc77d1f4e7764b008498f9b0d34bf8cb"
     ]
    },
    "id": "3u6j4poeow1U",
    "outputId": "1f6cc007-df43-47e0-f316-ac0645bc4ea5"
   },
   "outputs": [],
   "source": [
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "texts = [doc[\"text\"] for doc in documents]\n",
    "metas = [doc[\"metadata\"] for doc in documents]\n",
    "ids = [doc[\"id\"] for doc in documents]\n",
    "embeddings = embed_model.encode(texts, show_progress_bar=True)\n",
    "dimension = embeddings.shape[1]\n",
    "faiss_index = faiss.IndexFlatL2(dimension)\n",
    "faiss_index.add(np.array(embeddings))\n",
    "doc_lookup = {i: {\"text\": texts[i], \"metadata\": metas[i]} for i in range(len(texts))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8jV5-aCrkkL"
   },
   "source": [
    "7. Function for retreiving top queries(change value of k as per requirements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ns38k7cUp4Fl"
   },
   "outputs": [],
   "source": [
    "def retrieve_top_k(query, k=3):\n",
    "    query_vec = embed_model.encode([query])\n",
    "    distances, indices = faiss_index.search(np.array(query_vec), k)\n",
    "    return [doc_lookup[idx][\"text\"] for idx in indices[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWBGUAzlrx_1"
   },
   "source": [
    "8. Setup the function for answering questions Using FLAN-T5 (Offline QA)[I have free usage policy for both OpenAI and pinecone]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "noiplD5No0n_"
   },
   "outputs": [],
   "source": [
    "def answer_query_offline(query, k=3):\n",
    "    top_chunks = retrieve_top_k(query, k)\n",
    "    context = \"\\n\\n\".join(top_chunks)\n",
    "    prompt = f\"Answer the question based on the following context:\\n\\n{context}\\n\\nQuestion: {query}\"\n",
    "    model = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", max_length=512)\n",
    "    response = model(prompt)\n",
    "    return response[0]['generated_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xq037KlisIms"
   },
   "source": [
    "9. Querying the model and getting the answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292,
     "referenced_widgets": [
      "5a004a50e1864c0db31ab2b8a7c0c668",
      "349c6f5a1ec2448d985f84416c72b602",
      "3caaeb3d8b194d3da90521859e07536e",
      "db8e0b9529a44117a87f8efc65704174",
      "2465a0fd7b944076a11683293a3ca174",
      "b05fa74a6ee642a481c6f651bc4bc6ca",
      "304b6df59b3b43e2bcd9529822d9b52c",
      "9f0f7067cfea48c48be305a398cdf94a",
      "3fab546e097745ee9f2e4edf78ae09d2",
      "6eef74bab54b4858acd4a28f5e2004bd",
      "91625bc883184aee90145d3c208360d6",
      "c9af7c7329224a61a1e0cfd9855f11e0",
      "f07e2b9ecb4d417dbd36d269eca5ae9a",
      "013d49a3e6eb4c94b4a7fd396115c7b5",
      "29a96f0808a44f4eabed409341f6b3bf",
      "69c8446e9c2e42dfbc2e9798e58335d3",
      "fdc1c3a9ff174e559321e03111fbeddb",
      "6481d3b9a12c477b99cf9ab55b526759",
      "d83c8b1b25604a8d97fe8709e5db3911",
      "beaa9fb12de149fe8447e780b0a613fa",
      "520bfd415fdb436ea59f3e2895ce0845",
      "0541fb3bbd7d4410afc59ef7f0358c18",
      "1d36566a8ed64cba81751de47646f20d",
      "dc96a0f71dc54db388367b77cb5017b8",
      "c3178cf411154c2bbac8bf53d26b9718",
      "16d07360b7c142e8950a83bb69414f37",
      "73596f9fcf0f4dc3a8821daa61a25d59",
      "2b7d3d41b709499dbc7e98222ca5509f",
      "5d1ad13cd04f4a93bf230ddb3a823f7f",
      "49db3b5db7b0464bb4e00e3ee7c18056",
      "cd12b3f9a1a84e8a813d0aba18781941",
      "c220adbcdf21472d8d1c0fd46d040e75",
      "78c1b0fd7fcc46829b72d67e3442adff",
      "c726dc74064e46a2acb9b672e1b80e23",
      "1b534926889548f69098235a1daaf15d",
      "0f0bbc63d8de40ff8e82fb677ec06cf3",
      "dd769a9623e440c79d6fcbdbcfdd1dfe",
      "62bf057b044b4648a7b54ad61c39e1af",
      "0b622c133e3c4c7383f61a8a934af7a3",
      "bf004e4c8505443798b5fb47ed0f9399",
      "497d2eec7af9428e89d9bb083b7ddec6",
      "54bce1a4e6134bd4a49e41ad1ae0a805",
      "8044d2675638474fa8405369d576d8f4",
      "0b25ae7a61e34bc39ab2de31b4649b77",
      "ee6ce5d9997b4935805f3f89e536e764",
      "efa37d2e363f4b34a56ee4d155794cfa",
      "d295110ad34544c69da1e7d399097aab",
      "6abc7073cf4f49618f2a25738b4f5150",
      "590389f821594dd4afb92f20ddf9318b",
      "c6e3a59d0f444b04ba9b99212e5c1d12",
      "346551d7020a4d999d0df71ebaff97d2",
      "8e96e7fcec294d2c978f3378093fac16",
      "1b0aacf9f2e248af8e7719df5be61718",
      "b3d82c84cc564895ae5e04da1a4de76a",
      "7ae3c6250ebe4c04bce17f2e825953b9",
      "5c39a6a5f6e34bb6bd5b87fc10e2c209",
      "22e70082c1f84f82a83233153c71cb5a",
      "9e9552eb02db4540a733207e9a84a37b",
      "aa138b84080e4b149c15b0bac8802010",
      "e092a6b93dbb4fa59856e52b42beca63",
      "b198ff25ff6e480ca3f551e9c77b0366",
      "ba0dfa3e382645de82192bf70dc80c9b",
      "1c3adb1512e348c380b6a7d69a09f22f",
      "26c9ea5be37549b7848a40c090574d6c",
      "d54e84a61d144be19c658d987ccb93c4",
      "9bb1f4fe8b844dbeb770e963670a75e9",
      "a53dcefb6fac44fba7d33613538ea60a",
      "3b338af842e3420ba1a1d83ee5188f6e",
      "79f311ff4324434d9b736e9e534e8272",
      "d549575695ae497fac57bed2a00d2023",
      "23b09a32054945f88db1b0906cf9f0e7",
      "d0141496ccb146fd9019993ed748b011",
      "66138600308f4539bcd899eb408d3867",
      "a3064a797ba04f9cafbdb57aa023112d",
      "3d5b26082152429b97e55e0e9608407e",
      "5091243bf50545d9a25bc2bdf8b81c31",
      "b701c4174e714169beddbb18f970cb24"
     ]
    },
    "id": "PJ3CBnNhpw7D",
    "outputId": "e00a56cb-44c8-4413-b7b1-c4322a724e3e"
   },
   "outputs": [],
   "source": [
    "query = \"What is the total experience mentioned in the document?\"   #change the query here\n",
    "answer = answer_query_offline(query)\n",
    "print(\"Answer:\\n\", answer)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
